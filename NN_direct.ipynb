{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "308f56e8",
   "metadata": {},
   "source": [
    "from Karlo.simulation.dataset_creation import survival_probability, intrinsic_gamma, measured_gamma\n",
    "from scipy import constants\n",
    "from scipy.interpolate import RegularGridInterpolator\n",
    "import numpy as np\n",
    "import concurrent.futures\n",
    "import os\n",
    "import time\n",
    "from functools import partial\n",
    "import math"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9895131a",
   "metadata": {},
   "source": [
    "def create_one_training_example(spectrum_parameters, lc_parameters, Eqg,\n",
    "                                spectrum_error=None, lc_error=None, E_min=10 ** 10.55, E_max=10 ** 13.7,\n",
    "                                z=0.035, photon_num=2000, interpolation_grid=None, t_observation=4 * 28 * 60,\n",
    "                                verbose=False, i=0):\n",
    "    photon_count = 0\n",
    "    tries_count = 0\n",
    "    intrinsic_time = None\n",
    "    kappa2 = measured_gamma.distanceContrib(z)\n",
    "    E_max = min([E_max, measured_gamma.max_energy(Eqg, t_observation, E_min, kappa2)])\n",
    "    if E_max <= E_min:\n",
    "        return np.nan, np.nan, i\n",
    "    if interpolation_grid is not None:\n",
    "        opacity_interpolator = RegularGridInterpolator((interpolation_grid[0],\n",
    "                                                        interpolation_grid[1]),\n",
    "                                                       interpolation_grid[2])\n",
    "    else:\n",
    "        opacity_interpolator = None\n",
    "    if verbose:\n",
    "        start_time = time.time()\n",
    "    try:\n",
    "        while photon_count < photon_num:\n",
    "            tries_count += 1\n",
    "            if tries_count > 3*photon_num:\n",
    "                return 0, 0, i#np.nan, np.nan, i\n",
    "            if lc_error is not None:\n",
    "                A1, mean1, sigma1, A2, mean2, sigma2 = np.abs(np.random.normal(list(lc_parameters), list(lc_error)))\n",
    "            else:\n",
    "                A1, mean1, sigma1, A2, mean2, sigma2 = lc_parameters\n",
    "            if spectrum_error is not None:\n",
    "                E0, alpha = np.abs(np.random.normal(list(spectrum_parameters), list(spectrum_error)))\n",
    "            else:\n",
    "                E0, alpha = spectrum_parameters\n",
    "            if intrinsic_time is None:\n",
    "                intrinsic_time = intrinsic_gamma.intrinsic_times(A1, mean1, sigma1, A2, mean2, sigma2, size=1)\n",
    "                intrinsic_energy = intrinsic_gamma.intrinsic_energy(E_min, E_max, E0, alpha, size=1)\n",
    "                if opacity_interpolator is None:\n",
    "                    opacity = survival_probability.opacity(intrinsic_energy[0], z, Eqg)\n",
    "                else:\n",
    "                    opacity = opacity_interpolator((intrinsic_energy[0], Eqg))\n",
    "                survival_prob = [np.exp(-opacity)]\n",
    "                survived_mask = [False]\n",
    "            else:\n",
    "                print(\"tusam\")\n",
    "                print(\"parameters\", A1, mean1,sigma1, A2, mean2, sigma2,)\n",
    "                intrinsic_time_tmp = intrinsic_gamma.intrinsic_times(A1, mean1,\n",
    "                                                                        sigma1, A2,\n",
    "                                                                        mean2, sigma2,\n",
    "                                                                        size=1)\n",
    "                print (\"time\", intrinsic_time_tmp)\n",
    "                intrinsic_time = np.concatenate([intrinsic_time, intrinsic_time_tmp])\n",
    "                intrinsic_energy = np.concatenate([intrinsic_energy,\n",
    "                                            intrinsic_gamma.intrinsic_energy(E_min, E_max,\n",
    "                                                                           E0, alpha, size=1)])\n",
    "                if opacity_interpolator is None:\n",
    "                    opacity = survival_probability.opacity(intrinsic_energy[-1], z, Eqg)\n",
    "                else:\n",
    "                    opacity = opacity_interpolator((intrinsic_energy[-1], Eqg))\n",
    "                survival_prob = np.concatenate([survival_prob, [np.exp(-opacity)]])\n",
    "                survived_mask = np.concatenate([survived_mask, [False]])\n",
    "            if t_observation > 0:\n",
    "                if (np.random.random() < survival_prob[-1]) and (\n",
    "                        intrinsic_time[-1] + measured_gamma.timeDelay(intrinsic_energy[-1], Eqg,\n",
    "                                                                  kappa2) - measured_gamma.timeDelay(E_min, Eqg,\n",
    "                                                                                                     kappa2) < t_observation):\n",
    "                    survived_mask[-1] = True\n",
    "                    photon_count += 1\n",
    "            else:\n",
    "                if np.random.random() < survival_prob[-1]:\n",
    "                    survived_mask[-1] = True\n",
    "                    photon_count += 1\n",
    "            if verbose:\n",
    "                if photon_count != 0:\n",
    "                    print(\"\\r\", photon_count, \"/\", photon_num, \"measured, ETA:\",\n",
    "                        round((time.time() - start_time) * (photon_num - photon_count) / photon_count, 1), \"s\", )#end=\"   \")\n",
    "\n",
    "        assert survived_mask.sum() == photon_num\n",
    "        measured_time = intrinsic_time[survived_mask] + measured_gamma.timeDelay(intrinsic_energy[survived_mask], Eqg,\n",
    "                                                                             kappa2)\n",
    "        measured_energy = measured_gamma.detectionEnergy(intrinsic_energy[survived_mask], z)\n",
    "        sort_index = np.argsort(measured_time)\n",
    "        measured_photons = np.vstack([measured_time - measured_time.min(), measured_energy]).T[sort_index]\n",
    "        intrinsic_photons = np.vstack([intrinsic_time, intrinsic_energy, survival_prob]).T[sort_index]\n",
    "        return measured_photons, intrinsic_photons, i\n",
    "    except Exception as e:\n",
    "        print(f\"Exception in worker: {e}\")\n",
    "        return np.nan, np.nan, i"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd00213b",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "#import Karlo.simulation.dataset_creation as dataset_creation\n",
    "\n",
    "test1 =[8.94252900e+12, 2.33950394e+00, 2.77742417e+01, 4.84852408e+03, 6.35956539e+02,\n",
    "        1.98512118e+01, 2.68348172e+03, 6.87631652e+02, 2.99792859e+23]\n",
    "test2 =[5.58642990e+12, 2.70467552e+00, 3.36315330e+01, 3.02226309e+03, 6.03053917e+02,\n",
    "        8.45283242e+01, 3.41768613e+03, 8.10011238e+02, 7.09404636e+22]\n",
    "\n",
    "\n",
    "opacity_grid, E_grid, Eqg_grid = np.load(\"./Karlo/extra/Opacity_grid_100x100.npz\").values()\n",
    "interpolation_grid = (E_grid, Eqg_grid, opacity_grid)\n",
    "opacity_grid, E_grid, Eqg_grid = np.load(\"./Karlo/extra/Opacity_grid_100x100.npz\").values()\n",
    "interpolation_grid = (E_grid, Eqg_grid, opacity_grid)\n",
    "x_measured, x_intrinsic, _ = create_one_training_example (spectrum_parameters=test1[:2],\n",
    "                                          lc_parameters=test2[2:8],\n",
    "                                          Eqg=test2[8], spectrum_error=(0., 0.24), lc_error=(6., 185., 301., 11., 220., 283.),\n",
    "                                          interpolation_grid=interpolation_grid, verbose=True)\n",
    "\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee5a9ba",
   "metadata": {},
   "source": [
    "intrinsic_time_tmp = intrinsic_gamma.intrinsic_times(36.97348000381039, 2646.740802502216, 252.9971913535279, \n",
    "                                                     97.7719096500802, 3594.565994303601, 309.76313898064205, size=1)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "521ba676",
   "metadata": {},
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "98b7b214",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import scipy\n",
    "import time\n",
    "\n",
    "nPhot = 2000\n",
    "#nPhot = 10\n",
    "path = './Codes/photonSurvivalProbability/Run2/TrainingSamples/'\n",
    "dir_list = os.listdir(path)\n",
    "fileList = [i for i in dir_list if 'TrainSample_N-20_z-' in i and '.txt' in i and 'Tovar' not in i]\n",
    "#fileList = [i for i in dir_list if 'Tovar_TrainSample_z-' in i and '.txt' in i]\n",
    "fileList.sort(key = lambda x: float(x.split('LambdaQG-')[1].split('.txt')[0]))\n",
    "#fileList = ['TrainSample_N-100_z-0.034_LambdaQG-2526479177.553053.txt']\n",
    "train_x = []\n",
    "train_y = []\n",
    "for i in fileList:\n",
    "    redshift = i.split('-')[2].split('_')[0]\n",
    "    LQG = float(i.split('LambdaQG-')[1].split('.txt')[0])\n",
    "    print(i, redshift, LQG)\n",
    "    infile = open(path + i, 'r')\n",
    "    lines = infile.readlines()\n",
    "    trainSample_x = []\n",
    "    for line in lines:\n",
    "        #print(line)\n",
    "        if line[0] == '[' and len(line) > 60:\n",
    "            #print(len(line))\n",
    "            trainSample_y = [str(LQG)]\n",
    "            trainSample_y += line.strip('[').strip(']\\n').split(',')\n",
    "            #train_y = np.array(line.strip('[').strip(']\\n').split(','), dtype=np.float32)\n",
    "        elif line[0] == '[' and len(line) < 60:\n",
    "            trainSample_y += line.strip('[').strip(']\\n').split(',')\n",
    "            #print(type(trainSample_y))\n",
    "            #print(trainSample_y)\n",
    "            train_y.append(trainSample_y)\n",
    "        #elif line[0] != '[' and len(trainSample_x) < nPhot:\n",
    "        elif line[0] != '[':\n",
    "            #print(line.split()[0] + line.split()[1])\n",
    "            try:\n",
    "                trainSample_x.append([line.split()[0], line.split()[1]])\n",
    "            except:\n",
    "                print(line)\n",
    "        #elif line[0] != '[' and len(trainSample_x) == nPhot:\n",
    "            if len(trainSample_x) == nPhot:\n",
    "                #print(trainSample_x)\n",
    "                train_x.append(trainSample_x)\n",
    "                trainSample_x = []\n",
    "            #trainSample_x = [[line.split()[0], line.split()[1]]]\n",
    "        #elif EOF:\n",
    "         #   print(trainSample_x)\n",
    "          #  train_x.append(trainSample_x)\n",
    "            \n",
    "train_x = np.array(train_x, dtype=np.float64)\n",
    "#print(train_x.shape)\n",
    "#print(train_x)\n",
    "train_x = train_x.reshape(train_x.shape[0], -1, order='F').T\n",
    "print(train_x.shape)\n",
    "#print(train_x)\n",
    "train_y = np.array(train_y, dtype=np.float32).T\n",
    "print(train_y.shape)\n",
    "#print(train_y)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "d6cae1b9",
   "metadata": {},
   "source": [
    "plt.hist(train_x[:,0][:2000], bins=100)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fe54069",
   "metadata": {},
   "source": [
    "import Karlo.simulation.dataset_creation as dataset_creation"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aed20e32",
   "metadata": {},
   "source": [
    "opacity_grid, E_grid, Eqg_grid = np.load(\"./Karlo/extra/Opacity_grid_100x100.npz\").values()\n",
    "interpolation_grid = (E_grid, Eqg_grid, opacity_grid)\n",
    "x_measured, x_intrinsic, _ = dataset_creation.create_one_training_example (spectrum_parameters=[6.37540843e+12, 2.39079769e+00],\n",
    "                                          lc_parameters=[8.72911505e+01, 2.22771660e+03, 1.48336327e+03, 2.42958858e+01, 4.24120223e+03, 7.05215115e+02],\n",
    "                                          Eqg=5.19556821e+16, spectrum_error=(0., 0.24), lc_error=(6., 185., 301., 11., 220., 283.),\n",
    "                                          interpolation_grid=interpolation_grid, verbose=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568e6e3f",
   "metadata": {},
   "source": [
    "opacity_grid, E_grid, Eqg_grid = np.load(\"./Karlo/extra/Opacity_grid_100x100.npz\").values()\n",
    "interpolation_grid = (E_grid, Eqg_grid, opacity_grid)\n",
    "x_measured, x_intrinsic, _ = dataset_creation.create_one_training_example (spectrum_parameters=test1[:2],\n",
    "                                          lc_parameters=test2[2:8],\n",
    "                                          Eqg=test2[8], spectrum_error=(0., 0.24), lc_error=(6., 185., 301., 11., 220., 283.),\n",
    "                                          interpolation_grid=interpolation_grid, verbose=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae9c0d1",
   "metadata": {},
   "source": [
    "opacity_grid, E_grid, Eqg_grid = np.load(\"./Karlo/extra/Opacity_grid_100x100.npz\").values()\n",
    "interpolation_grid = (E_grid, Eqg_grid, opacity_grid)\n",
    "x_measured, x_intrinsic, _ = dataset_creation.create_one_training_example (spectrum_parameters=test2[:2],\n",
    "                                          lc_parameters=test2[2:8],\n",
    "                                          Eqg=test2[8], spectrum_error=(0., 0.24), lc_error=(6., 185., 301., 11., 220., 283.),\n",
    "                                          interpolation_grid=interpolation_grid, verbose=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e14346d1",
   "metadata": {},
   "source": [
    "x_measured[:,0].min(), x_measured[:,0].max()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b9774d6e",
   "metadata": {},
   "source": [
    "x_intrinsic[:,0].min(), x_intrinsic[:,0].max()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4bfd6c4c",
   "metadata": {},
   "source": [
    "_ = plt.hist([x_measured[:,0], x_intrinsic[:,0]],  bins=50, range=[0, 10000])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8037f71b",
   "metadata": {},
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy.stats import gaussian_kde\n",
    "import scipy.stats\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "\n",
    "def density_color_mask(x, y, small_size):\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    xy = (np.vstack([x.ravel(), y.ravel()]))\n",
    "    if x.shape[0] > small_size:\n",
    "        small_sample = np.random.choice(range(x.shape[0]), size=small_size)\n",
    "        z = gaussian_kde(xy[:, small_sample], bw_method='silverman')(xy)\n",
    "    else:\n",
    "        z = gaussian_kde(xy, bw_method='silverman')(xy)\n",
    "    idx = z.argsort()\n",
    "    x, y, z = x[idx], y[idx], z[idx]\n",
    "    return x, y, z\n",
    "\n",
    "\n",
    "def plot_correlation(true, prediction, axis, name=\"\", small_size=15000, true_name=\"true\", limit=None):\n",
    "    if type(true) is tuple or type(true) is list:\n",
    "        cmaps = ['Purples', 'Greens', 'Reds', 'Blues', 'Oranges', 'YlOrBr',\n",
    "                 'YlOrRd', 'OrRd', 'PuRd', 'RdPu', 'BuPu', 'GnBu', 'PuBu', 'YlGnBu',\n",
    "                 'PuBuGn', 'BuGn', 'YlGn']\n",
    "        axis.set_xlabel(xlabel=true_name)\n",
    "        axis.set_ylabel(ylabel=\"NN estimated\")\n",
    "        if limit is None:\n",
    "            limit = (true[0].min(), true[0].max())\n",
    "        if (type(name) is not list) and (type(name) is not tuple or len(name) == 1):\n",
    "            name = [str(i) for i in range(len(true))]\n",
    "        for i in range(len(true)):\n",
    "            limit = (min(limit[0], min(true[i].min(), prediction[i].min())),\n",
    "                     max(limit[1], max(true[i].max(), prediction[i].max())))\n",
    "            t, p, z = density_color_mask(true[i], prediction[i], small_size)\n",
    "            axis.scatter(np.array(t).flatten(),\n",
    "                         np.array(p).flatten(),\n",
    "                         c=z, label=name[i], s=1, cmap=cmaps[i])\n",
    "    else:\n",
    "        cmaps = ['viridis', 'plasma', 'inferno', 'magma', 'cividis']\n",
    "        axis.set_xlabel(xlabel=name + \" \" + true_name)\n",
    "        axis.set_ylabel(ylabel=name + \" NN estimated\")\n",
    "        if limit is None:\n",
    "            limit = (min(true.min(), prediction.min()),\n",
    "                    max(true.max(), prediction.max()))\n",
    "        t, p, z = density_color_mask(true, prediction, small_size)\n",
    "        scatter=axis.scatter(np.array(t).flatten(),\n",
    "                             np.array(p).flatten(),\n",
    "                             c=z, label=name, s=1, cmap=cmaps[0])\n",
    "        cbar = plt.colorbar(scatter, ax=axis, pad=0.02)\n",
    "        cbar.ax.set_ylabel(\"Points Density\", rotation=270, labelpad=-15)\n",
    "        cbar.set_ticks([z.min(), z.max()])\n",
    "        cbar.set_ticklabels(['low', 'high'])\n",
    "    axis.plot([limit[0], limit[1]], [limit[0], limit[1]], c='red', linestyle=\"dashed\", alpha=0.9)\n",
    "    lgnd = axis.legend(scatterpoints=1, loc='lower right')\n",
    "    axis.set_facecolor(\"white\")\n",
    "    limit = (limit[0] - 0.05 * (limit[1] - limit[0]), limit[1] + 0.05 * (limit[1] - limit[0]))\n",
    "    axis.set(xlim=limit, ylim=limit)\n",
    "    for i, handle in enumerate(lgnd.legend_handles[0:-1]):\n",
    "        handle.set_sizes([10.0])\n",
    "        handle.set_color(matplotlib.cm.get_cmap(cmaps[i])(0.7))\n",
    "    return axis"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65a029b",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "adacbb9f",
   "metadata": {},
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "import scipy\n",
    "import scipy.stats\n",
    "import datetime\n",
    "from scipy.stats.sampling import NumericalInversePolynomial\n",
    "from scipy import constants\n",
    "from scipy import integrate\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.integrate import quad\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "def doubleGauss(x, A1, mu1, sigma1, A2, mu2, sigma2):\n",
    "    return np.exp(-0.5*((x-mu1)/sigma1)**2)*A1 + np.exp(-0.5*((x-mu2)/sigma2)**2)*A2\n",
    "\n",
    "\n",
    "def powerLaw(x, N0, alpha):\n",
    "    x0 = 10.**11\n",
    "    return N0 * np.power(x/x0, alpha)    \n",
    "\n",
    "\n",
    "def powerLaw2(x, N0, alpha):\n",
    "    x0 = 11.\n",
    "    return alpha * (x - x0) + N0\n",
    "    \n",
    "\n",
    "\n",
    "def fitDistributions(sample):\n",
    "    #fig, (ax1, ax2) = plt.subplots(2, 1,figsize=[10, 9])\n",
    "    emissionTime = sample[:,0]\n",
    "    numBins1 = 30\n",
    "    #ax1.hist(emissionTime, density=False, bins=numBins1)\n",
    "    data_entries, bins = np.histogram(emissionTime, bins=numBins1)\n",
    "    binscenters = np.array([0.5 * (bins[i] + bins[i+1]) for i in range(numBins1)])\n",
    "    popt1, pcov1 = curve_fit(doubleGauss, xdata=binscenters, ydata=data_entries, \n",
    "                             p0=[100., 2000., 2000., 50., 6000., 1000.])\n",
    "    emissionEnergy = sample[:,1]\n",
    "    numBins2 = 20\n",
    "    logbins = np.logspace(np.log10(np.min(emissionEnergy)),np.log10(np.max(emissionEnergy)), numBins2+1)\n",
    "    data_entries, bins = np.histogram(emissionEnergy, bins=logbins)\n",
    "    binscenters = np.array([np.sqrt(logbins[i] * logbins[i+1]) for i in range(len(logbins)-1)])\n",
    "    popt2, pcov2 = curve_fit(powerLaw, xdata=binscenters, ydata=data_entries, p0=[100., -2.], bounds=((0., -10.), (np.inf, 0.)))\n",
    "    return list(popt1), list(popt2)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c9a82138",
   "metadata": {},
   "source": [
    "lc, spect = fitDistributions(x[120])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "db6f5f21",
   "metadata": {},
   "source": [
    "y[120, :]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "d02593a7",
   "metadata": {},
   "source": [
    "plt.hist(x[120, :, 0], bins=30)\n",
    "plt.plot(np.linspace(3600, 10), doubleGauss(np.linspace(3600, 10), lc[0],lc[1],lc[2],lc[3],lc[4],lc[5]))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "71e84c62",
   "metadata": {},
   "source": [
    "print(lc[0], y[120, 2])\n",
    "print(lc[1], y[120, 3])\n",
    "print(lc[2], y[120, 4])\n",
    "print(lc[3], y[120, 5])\n",
    "print(lc[4], y[120, 6])\n",
    "print(lc[5], y[120, 7])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c87960d4",
   "metadata": {},
   "source": [
    "x, y = np.load(\"./Karlo/extra/trainset_p2000n1000_0.npz\").values()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "cc8a2be5",
   "metadata": {},
   "source": [
    "fitDistributions(x[0])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "99a9364f",
   "metadata": {},
   "source": [
    "plt.hist(np.log10(x[0,:,0]), bins=100)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "3ac7e57e",
   "metadata": {},
   "source": [
    "x[0,:,0].shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "9f2d68b8",
   "metadata": {},
   "source": [
    "def liv_ann(arhitecture, x_shape):\n",
    "    input_x = tf.keras.layers.Input(shape=x_shape[1:], name='input')\n",
    "    x = tf.keras.layers.Flatten(name=\"flatten\")(input_x)\n",
    "    x = tf.keras.layers.BatchNormalization(name=\"Normalization\")(x)\n",
    "    assert len(arhitecture[\"units\"]) == len(arhitecture[\"activations\"])\n",
    "    for i in range(len(arhitecture[\"units\"])-1):\n",
    "        x = tf.keras.layers.Dense(units=arhitecture[\"units\"][i], activation=arhitecture[\"activations\"][i],\n",
    "                                  name=\"dense\" + str(i))(x)\n",
    "        x = tf.keras.layers.BatchNormalization(name=\"Normalization\"+str(i))(x)\n",
    "    output = []\n",
    "    for i in range(arhitecture[\"units\"][-1]):\n",
    "        output.append(tf.keras.layers.Dense(units=1,\n",
    "                                            activation=arhitecture[\"activations\"][-1],\n",
    "                                            name=\"output\" + str(i))(x))\n",
    "    model = tf.keras.Model(inputs=(input_x), outputs=output, name=\"ann_liv\")\n",
    "    return model"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "a8fb2dc6",
   "metadata": {},
   "source": [
    "errors = [1., 1/0.24, 1/6., 1/185., 1/301., 1/11., 1/220., 1/283., 1]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "59049e9b",
   "metadata": {},
   "source": [
    "arhitecture = {\"units\" : [256, 128, 16, 1],\n",
    "              \"activations\": [\"leaky_relu\", \"leaky_relu\", \"leaky_relu\", \"linear\"]}\n",
    "model = liv_ann(arhitecture, x.shape)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "d366d3f9",
   "metadata": {},
   "source": [
    "#model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.05), loss=\"mse\")\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.01), loss=\"mse\")\n",
    "              #loss=[\"mse\",\"mse\",\"mse\",\"mse\",\"mse\",\"mse\",\"mse\",\"mse\",\"mse\"], \n",
    "              #loss_weights=[1., 1/0.24, 1/6., 1/185., 1/301., 1/11., 1/220., 1/283., 1])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "10d0a785",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "model.fit(x_s,y_p, batch_size=1024, validation_split=0.25, epochs=1000)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "36f76987",
   "metadata": {},
   "source": [
    "p = model.predict(x_s)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "5b3b8e19",
   "metadata": {},
   "source": [
    "fig_correlation, ax = plt.subplots(figsize=(5, 5))\n",
    "#plot_correlation(y_prepared[-1], p, ax, limit=[0,30])\n",
    "plot_correlation(y_p, p, ax)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "18a6886c",
   "metadata": {},
   "source": [
    "y_p"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "cd577d73",
   "metadata": {},
   "source": [
    "p"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "c8d8d6dd",
   "metadata": {},
   "source": [
    "np.sqrt(np.median(np.square(y_p-p)))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b98651",
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LIV_NN",
   "language": "python",
   "name": "kmrakovc_liv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
